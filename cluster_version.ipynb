{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[K     |████████████████████████████████| 505 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2,>=1.22.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.0 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[K     |████████████████████████████████| 345 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/sfatimahazzahra/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Installing collected packages: tzdata, pytz, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.1 pytz-2024.1 tzdata-2024.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# @title import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title import dataset\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/miguroi/bcc-intern/main/Agrofood_co2_emission.csv\"\n",
    "    )\n",
    "\n",
    "data.rename(columns={'Area':'area', 'Year':'year', 'Savanna fires':'savanna_fires', 'Forest fires':'forest_fires', 'Crop Residues':'crop_residues', 'Rice Cultivation':'rice_cultivation', 'Drained organic soils (CO2)': 'co2', 'Pesticides Manufacturing': 'pesticides_manufacture', 'Food Transport': 'food_transport', 'Forestland':'forestland', 'Net Forest conversion': 'net_forest_conversion', 'Food Household Consumption': 'food_household_consumption', 'Food Retail':'food_retail', 'On-farm Electricity Use':'on_farm_electricity', 'Food Packaging':'food_packaging', 'Agrifood Systems Waste Disposal': 'agrifood_systems_waste_disposal', 'Food Processing':'food_processing', 'Fertilizers Manufacturing':'fertilizers_manufacture', 'IPPU':'ippu', 'Manure applied to Soils':'manure_soils', 'Manure left on Pasture':'manure_pasture', 'Manure Management':'manure_management', 'Fires in organic soils':'fires_organic_soils', 'Fires in humid tropical forests':'fires_tropical_forests', 'On-farm energy use':'on_farm_energy', 'Rural population':'rural_population', 'Urban population':'urban_population', 'Total Population - Male':'total_male', 'Total Population - Female':'total_female', 'Average Temperature °C':'average_temperature'}, inplace=True)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title grouping by sectors\n",
    "\n",
    "total_sectors = {\n",
    "    'Kebakaran': data[['savanna_fires', 'forest_fires', 'fires_organic_soils', 'fires_tropical_forests']].sum(axis=1),\n",
    "    'Pertanian': data[['crop_residues', 'rice_cultivation', 'co2', 'manure_soils', 'manure_pasture', 'manure_management']].sum(axis=1),\n",
    "    'Industri Pertanian': data[['fertilizers_manufacture', 'pesticides_manufacture']].sum(axis=1),\n",
    "    'Transportasi dan Distribusi Makanan': data[['food_transport', 'food_retail', 'food_packaging']].sum(axis=1),\n",
    "    'Konsumsi Makanan': data['food_household_consumption'],\n",
    "    'Pengolahan Makanan': data['food_processing'],\n",
    "    'Industri': data['ippu'],\n",
    "    'Pengolahan Limbah Pertanian': data['agrifood_systems_waste_disposal']\n",
    "}\n",
    "\n",
    "total_sectors_df = pd.DataFrame(total_sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, total_sectors_df], axis=1)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title grouping by continents\n",
    "\n",
    "def group_countries_by_continent(countries):\n",
    "    continents = {\n",
    "        'Africa': [],\n",
    "        'Asia': [],\n",
    "        'Europe': [],\n",
    "        'North America': [],\n",
    "        'Oceania': [],\n",
    "        'South America': [],\n",
    "        'Other': []\n",
    "    }\n",
    "\n",
    "    country_to_continent = {\n",
    "        # Africa\n",
    "        'Morocco':'Africa', 'Mozambique':'Africa', 'Namibia':'Africa', 'Niger':'Africa', 'Nigeria':'Africa',\n",
    "        'Rwanda':'Africa', 'Saint Helena, Ascension and Tristan da Cunha':'Africa', 'Sao Tome and Principe':'Africa',\n",
    "        'Senegal':'Africa', 'Seychelles':'Africa', 'Sierra Leone':'Africa', 'Somalia':'Africa', 'South Africa':'Africa',\n",
    "        'South Sudan':'Africa', 'Sudan':'Africa', 'Eswatini':'Africa', 'Tanzania':'Africa', 'Togo':'Africa',\n",
    "        'Tunisia':'Africa', 'Uganda':'Africa', 'Western Sahara':'Africa', 'Zambia':'Africa', 'Zimbabwe':'Africa',\n",
    "        'Madagascar':'Africa', 'Malawi':'Africa', 'Mali':'Africa', 'Mauritania':'Africa', 'Mauritius':'Africa',\n",
    "        'Mayotte':'Africa', 'Lesotho':'Africa', 'Liberia':'Africa', 'Libya':'Africa',\n",
    "\n",
    "        # Asia\n",
    "        'Afghanistan':'Asia', 'Armenia':'Asia', 'Azerbaijan':'Asia', 'Bahrain':'Asia', 'Bangladesh':'Asia',\n",
    "        'Bhutan':'Asia', 'Brunei Darussalam':'Asia', 'Cambodia':'Asia', 'China':'Asia', 'China, Hong Kong SAR':'Asia',\n",
    "        'China, Macao SAR':'Asia', 'China, mainland':'Asia', 'China, Taiwan Province of':'Asia', 'Cyprus':'Asia',\n",
    "        'Georgia':'Asia', 'India':'Asia', 'Indonesia':'Asia', 'Iran (Islamic Republic of)':'Asia', 'Iraq':'Asia',\n",
    "        'Israel':'Asia', 'Japan':'Asia', 'Jordan':'Asia', 'Kazakhstan':'Asia', 'Kuwait':'Asia', 'Kyrgyzstan':'Asia',\n",
    "        'Lao People\\'s Democratic Republic':'Asia', 'Lebanon':'Asia', 'Malaysia':'Asia', 'Maldives':'Asia',\n",
    "        'Mongolia':'Asia', 'Myanmar':'Asia', 'Nepal':'Asia', 'Oman':'Asia', 'Pakistan':'Asia', 'Palestine':'Asia',\n",
    "        'Philippines':'Asia', 'Qatar':'Asia', 'Republic of Korea':'Asia', 'Russian Federation':'Asia',\n",
    "        'Saudi Arabia':'Asia', 'Singapore':'Asia', 'Sri Lanka':'Asia', 'Syrian Arab Republic':'Asia', 'Tajikistan':'Asia',\n",
    "        'Thailand':'Asia', 'Timor-Leste':'Asia', 'Turkey':'Asia', 'Turkmenistan':'Asia', 'United Arab Emirates':'Asia',\n",
    "        'Uzbekistan':'Asia', 'Viet Nam':'Asia', 'Yemen':'Asia',\n",
    "\n",
    "        # Europe\n",
    "        'Albania':'Europe', 'Andorra':'Europe', 'Austria':'Europe', 'Belarus':'Europe', 'Belgium':'Europe',\n",
    "        'Bosnia and Herzegovina':'Europe', 'Bulgaria':'Europe', 'Croatia':'Europe', 'Czechia':'Europe',\n",
    "        'Denmark':'Europe', 'Estonia':'Europe', 'Finland':'Europe', 'France':'Europe', 'Germany':'Europe',\n",
    "        'Greece':'Europe', 'Hungary':'Europe', 'Iceland':'Europe', 'Ireland':'Europe', 'Italy':'Europe',\n",
    "        'Latvia':'Europe', 'Lithuania':'Europe', 'Luxembourg':'Europe', 'Malta':'Europe', 'Monaco':'Europe',\n",
    "        'Montenegro':'Europe', 'Netherlands':'Europe', 'North Macedonia':'Europe', 'Norway':'Europe', 'Poland':'Europe',\n",
    "        'Portugal':'Europe', 'Romania':'Europe', 'San Marino':'Europe', 'Serbia':'Europe', 'Slovakia':'Europe',\n",
    "        'Slovenia':'Europe', 'Spain':'Europe', 'Sweden':'Europe', 'Switzerland':'Europe', 'Ukraine':'Europe',\n",
    "        'United Kingdom of Great Britain and Northern Ireland':'Europe', 'Isle of Man':'Europe',\n",
    "\n",
    "        # North America\n",
    "        'Antigua and Barbuda':'North America', 'Bahamas':'North America', 'Barbados':'North America', 'Belize':'North America',\n",
    "        'Canada':'North America', 'Costa Rica':'North America', 'Cuba':'North America', 'Dominica':'North America',\n",
    "        'Dominican Republic':'North America', 'El Salvador':'North America', 'Grenada':'North America', 'Guatemala':'North America',\n",
    "        'Haiti':'North America', 'Honduras':'North America', 'Jamaica':'North America', 'Mexico':'North America',\n",
    "        'Nicaragua':'North America', 'Panama':'North America', 'Saint Kitts and Nevis':'North America', 'Saint Lucia':'North America',\n",
    "        'Saint Vincent and the Grenadines':'North America', 'Trinidad and Tobago':'North America', 'United States of America':'North America',\n",
    "\n",
    "        # Oceania\n",
    "        'Australia':'Oceania', 'Fiji':'Oceania', 'Kiribati':'Oceania', 'Marshall Islands':'Oceania',\n",
    "        'Micronesia (Federated States of)':'Oceania', 'Nauru':'Oceania', 'New Zealand':'Oceania', 'Palau':'Oceania',\n",
    "        'Papua New Guinea':'Oceania', 'Samoa':'Oceania', 'Solomon Islands':'Oceania', 'Tonga':'Oceania',\n",
    "        'Tuvalu':'Oceania', 'Vanuatu':'Oceania',\n",
    "\n",
    "        # South America\n",
    "        'Argentina':'South America', 'Bolivia (Plurinational State of)':'South America', 'Brazil':'South America',\n",
    "        'Chile':'South America', 'Colombia':'South America', 'Ecuador':'South America', 'Guyana':'South America',\n",
    "        'Paraguay':'South America', 'Peru':'South America', 'Suriname':'South America', 'Uruguay':'South America',\n",
    "        'Venezuela (Bolivarian Republic of)':'South America',\n",
    "\n",
    "        # Other\n",
    "        'Montserrat':'Other', 'Niue':'Other', 'Puerto Rico':'Other', 'Tokelau':'Other',\n",
    "        'United States Virgin Islands':'Other', 'Wallis and Futuna Islands':'Other', 'Falkland Islands (Malvinas)':'Other',\n",
    "        'French Polynesia':'Other', 'Greenland':'Other', 'Guam':'Other', 'American Samoa':'Other', 'Aruba':'Other',\n",
    "        'Bermuda':'Other', 'British Virgin Islands':'Other', 'Cayman Islands':'Other', 'Cook Islands':'Other',\n",
    "        'Curaçao':'Other', 'Faroe Islands':'Other', 'French Guiana':'Other', 'Gibraltar':'Other', 'Guadeloupe':'Other',\n",
    "        'Martinique':'Other', 'Mayotte':'Other', 'Montenegro':'Other', 'New Caledonia':'Other', 'Pitcairn':'Other',\n",
    "        'Réunion':'Other', 'Saint Barthélemy':'Other', 'Saint Martin (French part)':'Other', 'Sint Maarten (Dutch part)':'Other',\n",
    "        'South Georgia and the South Sandwich Islands':'Other', 'Svalbard and Jan Mayen Islands':'Other', 'Turks and Caicos Islands':'Other'\n",
    "    }\n",
    "\n",
    "    for country in countries:\n",
    "        continent = country_to_continent.get(country, 'Other')\n",
    "        continents[continent].append(country)\n",
    "\n",
    "    return continents\n",
    "\n",
    "countries = [\n",
    "    'Morocco', 'Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda',\n",
    "    'Saint Helena, Ascension and Tristan da Cunha', 'Sao Tome and Principe',\n",
    "    'Senegal', 'Seychelles', 'Sierra Leone', 'Somalia', 'South Africa',\n",
    "    'South Sudan', 'Sudan', 'Eswatini', 'Tanzania', 'Togo', 'Tunisia',\n",
    "    'Uganda', 'Western Sahara', 'Zambia', 'Zimbabwe', 'Madagascar', 'Malawi',\n",
    "    'Mali', 'Mauritania', 'Mauritius', 'Mayotte', 'Lesotho', 'Liberia', 'Libya',\n",
    "\n",
    "    # Asia\n",
    "    'Afghanistan', 'Armenia', 'Azerbaijan', 'Bahrain', 'Bangladesh', 'Bhutan', 'Brunei Darussalam', 'Cambodia',\n",
    "    'China', 'China, Hong Kong SAR', 'China, Macao SAR', 'China, mainland', 'China, Taiwan Province of', 'Cyprus',\n",
    "    'Georgia', 'India', 'Indonesia', 'Iran (Islamic Republic of)', 'Iraq', 'Israel', 'Japan', 'Jordan', 'Kazakhstan',\n",
    "    'Kuwait', 'Kyrgyzstan', 'Lao People\\'s Democratic Republic', 'Lebanon', 'Malaysia', 'Maldives', 'Mongolia',\n",
    "    'Myanmar', 'Nepal', 'Oman', 'Pakistan', 'Palestine', 'Philippines', 'Qatar', 'Republic of Korea', 'Russian Federation',\n",
    "    'Saudi Arabia', 'Singapore', 'Sri Lanka', 'Syrian Arab Republic', 'Tajikistan', 'Thailand', 'Timor-Leste', 'Turkey',\n",
    "    'Turkmenistan', 'United Arab Emirates', 'Uzbekistan', 'Viet Nam', 'Yemen',\n",
    "\n",
    "    # Europe\n",
    "    'Albania', 'Andorra', 'Austria', 'Belarus', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Czechia',\n",
    "    'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy',\n",
    "    'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Monaco', 'Montenegro', 'Netherlands', 'North Macedonia', 'Norway',\n",
    "    'Poland', 'Portugal', 'Romania', 'San Marino', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland',\n",
    "    'Ukraine', 'United Kingdom of Great Britain and Northern Ireland', 'Isle of Man',\n",
    "\n",
    "    # North America\n",
    "    'Antigua and Barbuda', 'Bahamas', 'Barbados', 'Belize', 'Canada', 'Costa Rica', 'Cuba', 'Dominica', 'Dominican Republic',\n",
    "    'El Salvador', 'Grenada', 'Guatemala', 'Haiti', 'Honduras', 'Jamaica', 'Mexico', 'Nicaragua', 'Panama',\n",
    "    'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Vincent and the Grenadines', 'Trinidad and Tobago', 'United States of America',\n",
    "\n",
    "    # Oceania\n",
    "    'Australia', 'Fiji', 'Kiribati', 'Marshall Islands', 'Micronesia (Federated States of)', 'Nauru', 'New Zealand', 'Palau',\n",
    "    'Papua New Guinea', 'Samoa', 'Solomon Islands', 'Tonga', 'Tuvalu', 'Vanuatu',\n",
    "\n",
    "    # South America\n",
    "    'Argentina', 'Bolivia (Plurinational State of)', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Guyana', 'Paraguay',\n",
    "    'Peru', 'Suriname', 'Uruguay', 'Venezuela (Bolivarian Republic of)',\n",
    "\n",
    "    # Other territories and regions (islands and territories)\n",
    "    'Montserrat', 'Niue', 'Puerto Rico', 'Tokelau', 'United States Virgin Islands', 'Wallis and Futuna Islands',\n",
    "    'Falkland Islands (Malvinas)', 'French Polynesia', 'Greenland', 'Guam', 'American Samoa', 'Aruba', 'Bermuda',\n",
    "    'British Virgin Islands', 'Cayman Islands', 'Cook Islands', 'Curaçao', 'Faroe Islands', 'French Guiana', 'Gibraltar',\n",
    "    'Guadeloupe', 'Martinique', 'Mayotte', 'Montenegro', 'New Caledonia', 'Pitcairn', 'Réunion', 'Saint Barthélemy',\n",
    "    'Saint Martin (French part)', 'Sint Maarten (Dutch part)', 'South Georgia and the South Sandwich Islands', 'Svalbard and Jan Mayen Islands',\n",
    "    'Turks and Caicos Islands'\n",
    "]\n",
    "\n",
    "grouped_countries = group_countries_by_continent(countries)\n",
    "\n",
    "for continent, countries_list in grouped_countries.items():\n",
    "    print(f'{continent}: {\", \".join(countries_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title grouping by continents (continue)\n",
    "\n",
    "# bikin list countries dari area\n",
    "countries = data['area'].unique()\n",
    "\n",
    "# bikin grouping negara berdasarkan benua\n",
    "grouped_countries = group_countries_by_continent(countries)\n",
    "\n",
    "# bikin kolom 'continent' di data\n",
    "data['continent'] = ''\n",
    "\n",
    "# nambahin value buat kolom 'continent' berdasarkan dictionary 'grouped_countries'\n",
    "for index, row in data.iterrows():\n",
    "    country = row['area']\n",
    "    continent = None\n",
    "    for key, value in grouped_countries.items():\n",
    "        if country in value:\n",
    "            continent = key\n",
    "            break\n",
    "    data.at[index, 'continent'] = continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title cleaning using knnimputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "imputed_columns = data.select_dtypes(include=['float64', 'int64']).columns # impute kolom-kolom numerik\n",
    "\n",
    "data[imputed_columns] = imputer.fit_transform(data[imputed_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X_cluster = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title encoding object columns\n",
    "\n",
    "kolom_objek = data.select_dtypes(include=object).columns.tolist()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "data_ohe = ohe.fit_transform(data[kolom_objek]).toarray()\n",
    "data_ohe = pd.DataFrame(data_ohe, columns=ohe.get_feature_names_out())\n",
    "\n",
    "data = pd.concat([data, data_ohe], axis=1)\n",
    "data = data.drop(kolom_objek, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster = X_cluster.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "hapus = ['fires_organic_soils', 'fires_tropical_forests', 'savanna_fires',\n",
    "                 'ippu','pesticides_manufacture', 'food_processing', 'fertilizers_manufacture','food_transport','food_packaging', 'food_retail',\n",
    "                 'rice_cultivation', 'manure_pasture', 'crop_residues', 'manure_soils','co2','manure_management','agrifood_systems_waste_disposal',\n",
    "                 'food_household_consumption']\n",
    "\n",
    "X_cluster.drop(columns=hapus, inplace=True)\n",
    "\n",
    "X_cluster.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title mengecek metode clustering\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.cluster import KMeans\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import davies_bouldin_score\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# X = data_train.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "k_range = range(2, 30)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    cluster_labels = kmeans.fit_predict(X_cluster)\n",
    "    silhouette_scores.append(silhouette_score(X_cluster, cluster_labels))\n",
    "\n",
    "plt.plot(k_range, silhouette_scores)\n",
    "plt.xlabel('Jumlah cluster')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Clustering without PCA\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "# nerapin algoritma KMeans pada data tanpa PCA\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_cluster)\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# hitung silhouette score\n",
    "silhouette_score_without_pca = silhouette_score(X_cluster, cluster_labels)\n",
    "\n",
    "# ngehitung jumlah cluster\n",
    "cluster_counts = pd.Series(cluster_labels).value_counts()\n",
    "\n",
    "print(\"Silhouette Score without PCA:\", silhouette_score_without_pca)\n",
    "print(\"Cluster Counts:\\n\", cluster_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title clustering all features using PCA & kmeans\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "# apply pca buat mengurangi dimensionality sebelum clustering\n",
    "pca = PCA(n_components=0.95)  # jaga 95% of variance\n",
    "X_pca = pca.fit_transform(X_cluster)\n",
    "\n",
    "# kmeans buat cluster data yang udah ditransformasi pakai PCA\n",
    "kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_pca.fit(X_pca)\n",
    "pca_cluster_labels = kmeans_pca.labels_\n",
    "\n",
    "# ngehitung silhouette score\n",
    "pca_silhouette_score = silhouette_score(X_pca, pca_cluster_labels)\n",
    "\n",
    "# ngehitung cluster counts\n",
    "pca_cluster_counts = pd.Series(pca_cluster_labels).value_counts()\n",
    "\n",
    "print(\"PCA Silhouette Score:\", pca_silhouette_score)\n",
    "print(\"PCA Cluster Counts:\\n\", pca_cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisasi clustering menggunakan PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot semua titik data dengan warna berdasarkan label kluster\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 0], c=pca_cluster_labels, cmap='viridis', s=50, alpha=0.5)\n",
    "\n",
    "# Plot pusat kluster\n",
    "plt.scatter(kmeans_pca.cluster_centers_[:, 0], kmeans_pca.cluster_centers_[:, 0], c='red', marker='x', s=200, label='Centroids')\n",
    "\n",
    "plt.title('Clustering using PCA and KMeans')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 1')\n",
    "plt.legend()\n",
    "plt.colorbar(label='Cluster')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans_pca.cluster_centers_\n",
    "print(\"Cluster Centroids:\\n\", centroids)\n",
    "\n",
    "# add cluster labels to X_cluster dataframe\n",
    "X_cluster['Cluster'] = pca_cluster_labels\n",
    "\n",
    "# compute mean/median values for each feature within each cluster\n",
    "cluster_profiles_mean = X_cluster.groupby('Cluster').mean()\n",
    "cluster_profiles_median = X_cluster.groupby('Cluster').median()\n",
    "\n",
    "print(\"Cluster Profiles (Mean):\\n\", cluster_profiles_mean)\n",
    "print(\"\\nCluster Profiles (Median):\\n\", cluster_profiles_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import seaborn as sns\n",
    "\n",
    "data_for_vis = cluster_profiles_mean.reset_index()\n",
    "\n",
    "# Parallel Coordinates Plot\n",
    "plt.figure(figsize=(50, 8))\n",
    "parallel_coordinates(data_for_vis, 'Cluster', colormap=plt.get_cmap(\"Set2\"))\n",
    "plt.title('Parallel Coordinates Plot for Cluster Centroids')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(cluster_profiles_mean.drop('year', axis=1).T, cmap='YlGnBu', annot=True)\n",
    "plt.title('Heatmap of Cluster Profiles')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Cluster', y='total_emission', data=X_cluster)\n",
    "plt.title('Box Plot of Total Emission by Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Cluster', y='average_temperature', data=X_cluster)\n",
    "plt.title('Box Plot of Total Emission by Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title prepare data for modelling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "y = data['average_temperature']\n",
    "X = data.drop(['average_temperature'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title model testing\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "svr_model = SVR(kernel='rbf')\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# training models\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "svr_model.fit(X_train, y_train)\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# prediksikan test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# evaluasi model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"MSE: {mse_rf}, R^2: {r2_rf}\")\n",
    "print()\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"MSE: {mse_gb}, R^2: {r2_gb}\")\n",
    "print()\n",
    "\n",
    "print(\"Support Vector Regression:\")\n",
    "print(f\"MSE: {mse_svr}, R^2: {r2_svr}\")\n",
    "print()\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"MSE: {mse_linear}, R^2: {r2_linear}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title checking for overfitting/target skewness\n",
    "\n",
    "# ngehitung mse buat train set\n",
    "train_mse_rf = mean_squared_error(y_train, rf_model.predict(X_train))\n",
    "train_mse_gb = mean_squared_error(y_train, gb_model.predict(X_train))\n",
    "train_mse_svr = mean_squared_error(y_train, svr_model.predict(X_train))\n",
    "train_mse_linear = mean_squared_error(y_train, linear_model.predict(X_train))\n",
    "\n",
    "# ngehitung perbedaan performa antara training dan testing\n",
    "performance_difference_rf = train_mse_rf - mse_rf\n",
    "performance_difference_gb = train_mse_gb - mse_gb\n",
    "performance_difference_svr = train_mse_svr - mse_svr\n",
    "performance_difference_linear = train_mse_linear - mse_linear\n",
    "\n",
    "def check_overfitting(performance_difference):\n",
    "    return abs(performance_difference) > 0.01\n",
    "\n",
    "overfitting_rf = check_overfitting(performance_difference_rf)\n",
    "overfitting_gb = check_overfitting(performance_difference_gb)\n",
    "overfitting_svr = check_overfitting(performance_difference_svr)\n",
    "overfitting_linear = check_overfitting(performance_difference_linear)\n",
    "\n",
    "results = {\n",
    "    \"Random Forest\": {\"Train MSE\": train_mse_rf, \"Test MSE\": mse_rf, \"Difference\": performance_difference_rf, \"Overfitting\": overfitting_rf},\n",
    "    \"Gradient Boosting\": {\"Train MSE\": train_mse_gb, \"Test MSE\": mse_gb, \"Difference\": performance_difference_gb, \"Overfitting\": overfitting_gb},\n",
    "    \"SVR\": {\"Train MSE\": train_mse_svr, \"Test MSE\": mse_svr, \"Difference\": performance_difference_svr, \"Overfitting\": overfitting_svr},\n",
    "    \"Linear Regression\": {\"Train MSE\": train_mse_linear, \"Test MSE\": mse_linear, \"Difference\": performance_difference_linear, \"Overfitting\": overfitting_linear}\n",
    "}\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(model_name)\n",
    "    print(metrics)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# jumlah folds buat cross-validation\n",
    "cv_folds = 5\n",
    "\n",
    "# perform cross-validation for each model\n",
    "cv_mse_rf = -cross_val_score(rf_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds).mean()\n",
    "cv_mse_gb = -cross_val_score(gb_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds).mean()\n",
    "cv_mse_svr = -cross_val_score(svr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds).mean()\n",
    "cv_mse_linear = -cross_val_score(linear_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds).mean()\n",
    "\n",
    "cv_mse_rf, cv_mse_gb, cv_mse_svr, cv_mse_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Jumlah folds untuk cross-validation\n",
    "cv_folds = 10\n",
    "\n",
    "# Melakukan cross-validation untuk setiap model\n",
    "cv_scores_rf = -cross_val_score(rf_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds)\n",
    "cv_scores_gb = -cross_val_score(gb_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds)\n",
    "cv_scores_svr = -cross_val_score(svr_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds)\n",
    "cv_scores_linear = -cross_val_score(linear_model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv_folds)\n",
    "\n",
    "# Mencetak hasil cross-validation\n",
    "print(\"Cross-Validation Scores RF:\")\n",
    "for i, score in enumerate(cv_scores_rf, 1):\n",
    "    print(f\"Fold {i}: {score}\")\n",
    "\n",
    "print(\"\\nCross-Validation Scores GB:\")\n",
    "for i, score in enumerate(cv_scores_gb, 1):\n",
    "    print(f\"Fold {i}: {score}\")\n",
    "\n",
    "print(\"\\nCross-Validation Scores SVR:\")\n",
    "for i, score in enumerate(cv_scores_svr, 1):\n",
    "    print(f\"Fold {i}: {score}\")\n",
    "\n",
    "print(\"\\nCross-Validation Scores Linear:\")\n",
    "for i, score in enumerate(cv_scores_linear, 1):\n",
    "    print(f\"Fold {i}: {score}\")\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "# Menghitung rata-rata dan standar deviasi dari setiap skor cross-validation untuk setiap model\n",
    "mean_cv_score_rf = np.mean(cv_scores_rf)\n",
    "std_cv_score_rf = np.std(cv_scores_rf)\n",
    "\n",
    "mean_cv_score_gb = np.mean(cv_scores_gb)\n",
    "std_cv_score_gb = np.std(cv_scores_gb)\n",
    "\n",
    "mean_cv_score_svr = np.mean(cv_scores_svr)\n",
    "std_cv_score_svr = np.std(cv_scores_svr)\n",
    "\n",
    "mean_cv_score_linear = np.mean(cv_scores_linear)\n",
    "std_cv_score_linear = np.std(cv_scores_linear)\n",
    "\n",
    "# Mencetak rata-rata dan standar deviasi dari setiap skor cross-validation untuk setiap model\n",
    "print(\"Mean Cross-Validation Scores RF:\", mean_cv_score_rf)\n",
    "print(\"Standard Deviation Cross-Validation Scores RF:\", std_cv_score_rf)\n",
    "\n",
    "print(\"\\nMean Cross-Validation Scores GB:\", mean_cv_score_gb)\n",
    "print(\"Standard Deviation Cross-Validation Scores GB:\", std_cv_score_gb)\n",
    "\n",
    "print(\"\\nMean Cross-Validation Scores SVR:\", mean_cv_score_svr)\n",
    "print(\"Standard Deviation Cross-Validation Scores SVR:\", std_cv_score_svr)\n",
    "\n",
    "print(\"\\nMean Cross-Validation Scores Linear:\", mean_cv_score_linear)\n",
    "print(\"Standard Deviation Cross-Validation Scores Linear:\", std_cv_score_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unused data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data_vis = data[['urban_population', 'total_emission']]\n",
    "data_vis['Cluster'] = pca_cluster_labels\n",
    "\n",
    "sns.pairplot(data_vis, hue='Cluster', palette='viridis', diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "ahc = linkage(X_cluster, method='ward')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "dendrogram(ahc, truncate_mode='level', p=2)\n",
    "plt.title('Dendrogram for Agglomerative Hierarchical Clustering')\n",
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Euclidean distance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
